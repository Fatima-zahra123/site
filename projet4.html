<html>
<head>
    <meta charset="UTF-8">
    <title>Application</title>
    <link rel="stylesheet"  href="style4.css">
</head>

<body>
<div class="container">
			<header>

			  <img src="img/12.png" class="logo">
				<nav>
					<ul >
						<li class="a" ><a href="index.html">l'Accueil</a></li>
						<li class="a"><a href="projet2.html">autour de IA</a></li>
						<li class="a"><a href="projet3.html">secteur de IA</a></li>
					<li class="a"><a href="projet4.html">les Applications</a></li>
						<li class="a"><a href="projet5.html">Inscription</a></li>
					</ul>
		         </nav>
				</header>
</div>

<div class="div1">
	<p class="d" style="font-size : 600% ;color :white" >Application</p>

</div>

<div class="div">
<img src="img/8.jpg"  style="width:90px ;height:90px">
<h2>AlphaGo</h2>
<br>
<p    align ="left"><b>AlphaGo</b> est le nom du programme d'intelligence artificielle (IA) développé par la société britannique <b>DeepMind</b> (acquise en 2014 par Google) pour affronter les meilleurs joueurs humains de go. <br>Accordant une place prépondérante à l'intuition, le go était le seul jeu de ce type pour lequel les humains se montraient encore supérieurs aux machines. Selon Demis Hassabis, l'un des fondateurs de DeepMind, ce jeu de réflexion offre un nombre de combinaisons « supérieur au nombre d'atomes que compte l'univers ».

<br><br>Mais tout a changé <b>en janvier 2016</b>, lorsque DeepMind a annoncé qu'<b>AlphaGo</b> avait battu Fan Hui, triple champion européen en titre du jeu de go. Quelques mois plus tard, l'IA défiait Lee Sedol, l'un des meilleurs joueurs professionnels du monde (9e dan). AlphaGo l'a battu par quatre victoires à une. En mai 2017, une nouvelle version du programme s'est attaquée au champion du monde en titre, Ke Jie, qu'il a vaincu en trois manches.<br><br>

<b>AlphaGo</b> utilise une méthode de calcul probabiliste dite <b>méthode Monte-Carlo</b> à laquelle sont associés deux réseaux neuronaux d'apprentissage profond ayant chacun une tâche différente :<br>
<ul>
<li>un premier appelé <b>policy network (réseau d'objectifs)</b> travaille à prédire le prochain coup ;
<li>un second appelé <b>value network (réseau de valeur)</b> estime l'issue favorable d'un mouvement à partir de la configuration du plateau de jeu.
</ul>
</p>
</div>
<div   class="div"  style="background :none;  box-shadow : 0 3px 10px rgba(0,0,0,0)">
<iframe width="560" height="490" src="https://www.youtube.com/embed/7sZ8TSQv6hk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</div>

<div class="div">
<img src="img/10.jfif"  style="width:90px ;height:90px">
<h2>Viv</h2><br>
<p>Les créateurs de Siri viennent de dévoiler Viv, un nouvel assistant virtuel capable d'accomplir beaucoup plus d'actions en associant les commandes vocales à des applications tierces. Viv sait passer une commande, peut réserver un hôtel ou un taxi et bien d'autres choses encore. Il est surtout conçu pour fonctionner sur différents types de terminaux afin de nous accompagner en toute circonstance.<br>Les professionnels qui disposent d'un ou d'une assistant(e) ont beaucoup de chance car ces personnes leur facilitent grandement la vie. Elles connaissent bien leurs habitudes, savent exactement à quel prestataire faire appel pour répondre à leurs demandes ; le tout dans les meilleurs délais. Les Siri (Apple), Google Now (Google), Cortana (Microsoft), ces assistants virtuels apparus ces dernières années dans nos smartphones, ont cette ambition, mais ils sont encore bien loin de l'efficacité des humains qu'ils tentent de copier.<br>Fruit de quatre années de développement, ce nouvel assistant est capable de répondre à des questions complexes et d'accomplir des tâches de façon très autonome. Au lieu de traiter les requêtes en lançant une recherche sur Internet, ce que font Siri et consorts, Viv se connecte directement aux applications et services en ligne adéquats. L'assistant est ainsi capable de faire des achats, des réservations et il sait à quels lieux correspondent les mots « maison », « chez moi », « bureau », etc.</p>
</div>

<div class="div"   style="background :none;  box-shadow : 0 3px 10px rgba(0,0,0,0)">
<iframe width="560" height="490" src="https://www.youtube.com/embed/Rblb3sptgpQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>


<div class="div">
<img src="img/m.jpg"  style="width:90px ;height:90px">
<h2>LipNet</h2><br>
<p>Désormais plus douée que le meilleur expert, <b>une intelligence artificielle peut lire sur les lèvres</b>.<br>La collaboration entre l’université d’Oxford et une filiale de Google, DeepMind, a créé une intelligence artificielle (IA) qui sait déchiffrer les mouvements des lèvres et les traduire en texte. Pour réussir cette performance, la machine s’est exercée sur près de 5000 heures de programmes tv de la chaîne BBC.<br><b>LipNet</b> est donc la première intelligence artificielle a faire mieux que les experts en terme d’exactitude : <b>son taux de précision est de 93,4%</b> contre 53,2 pour les personnes les plus douées. Par contre, LipNet n’est pas encore très entraînée à déchiffrer des vraies phrases échangées entre deux personnes, étant davantage aptes à reconnaître des phrases avec des structures précises.<br>Une équipe composée de <b>chercheurs de l'université d'Oxford et de DeepMind</b>, la filiale de Google spécialisée dans l'intelligence artificielle (IA), a mis au point une application de lecture sur les lèvres présentée comme beaucoup plus performante que les humains. Ils ont entrainé leur réseau neuronal à partir de 5.000 heures de programmes télévisés de la BBC (Newsnight, Question Time, The World Today). <b>L'échantillon contenait 118.000 phrases et 17.500 mots uniques.</b>

<br>

L’IA pourrait encore être améliorer et être utilisée par la suite pour de la reconnaissance vocale mais aussi en terme de doublage de film ou pour reconnaître des paroles dans un environnement bruyant. Cela pourrait aussi servir en terme de surveillance.</p>
</div>

<div class="div" style="background :none;  box-shadow : 0 3px 10px rgba(0,0,0,0)">
<iframe width="560" height="490" src="https://www.youtube.com/embed/fa5QGremQf8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>


<div class="div"  style="height :500px">
<h2>DeepStereo</h2><br>
<p> <b>DeepStereo</b> est un algorithme prédictif capable de produire une animation vidéo à partir de photos en recréant lui-même les images et les perspectives manquantes. Techniquement très performant, il est cependant encore trop exigeant en ressources système pour envisager une mise en service à brève échéance.<br>Baptisé<b> DeepStereo</b>, il est capable de transformer n'importe quelle séquence d'images en film en interpolant les trames manquantes. Par exemple, si l'algorithme dispose de deux clichés montrant seulement les façades droite et gauche d'une maison, il saura reconstituer la partie centrale de la demeure. Si on lui procure seulement cinq photos d'une pièce,<b> DeepStereo peut restituer des vues sous d'autres angles en « imaginant » ce qui devrait s'y trouver</b>. Comment cela fonctionne-t-il au juste ?<br>

<b>DeepStereo</b> s'appuie sur l'intelligence artificielle de Google. Il s'agit d'un réseau neuronal constitué de plusieurs couches. Les ingénieurs ont entraîné leur algorithme en utilisant le deep learning, une technique d'apprentissage automatique. Le système a été abreuvé avec 100.000 séquences tirées de Google Street View contenant des images de scènes de rue saisies depuis un véhicule en mouvement. Pour éprouver les capacités du réseau profond, les techniciens ont ensuite retiré une image dans chaque séquence et demandé à DeepStereo de la reconstituer en se basant seulement sur les autres images disponibles dans ladite séquence.</p>
</div>

<div class="div"  style="background :none;  box-shadow : 0 3px 10px rgba(0,0,0,0)">
<iframe  width="560" height="490" src="https://www.youtube.com/embed/maLxp2_JMyk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>





</body>

</html>